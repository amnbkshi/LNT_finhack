{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('lnt/train_aox2Jxw/train.csv', parse_dates=['Date.of.Birth', 'DisbursalDate'])\n",
    "test = pd.read_csv('lnt/test_bqCt9Pv.csv', parse_dates=['Date.of.Birth', 'DisbursalDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = test['UniqueID']\n",
    "y = train.iloc[:, -1]\n",
    "train.drop('loan_default', inplace=True, axis = 1)\n",
    "\n",
    "df = pd.concat([train, test], axis = 0)\n",
    "\n",
    "df.drop(['UniqueID', 'Employee_code_ID', 'supplier_id', 'Current_pincode_ID'], inplace=True, axis=1)\n",
    "df['Employment.Type'].fillna('temp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CREDIT.HISTORY.LENGTH'] = df['CREDIT.HISTORY.LENGTH'].apply(lambda x: x[0])\n",
    "df['AVERAGE.ACCT.AGE'] = df['AVERAGE.ACCT.AGE'].apply(lambda x: x[0])\n",
    "\n",
    "df['Date.of.Birth'] = np.abs(2019 - df['Date.of.Birth'].dt.year)\n",
    "df['DisbursalDate'] = df['DisbursalDate'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('No Bureau History Available', 0)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Sufficient History Not Available', 0)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Not Enough Info available on the customer', 0)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: No Activity seen on the customer (Inactive)',0)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: No Updates available in last 36 months', 0)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Only a Guarantor', 0)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: More than 50 active Accounts found',0)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('M-Very High Risk', 1)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('L-Very High Risk', 1)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('K-High Risk', 2)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('J-High Risk', 2)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('I-Medium Risk', 3)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('H-Medium Risk', 3)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('G-Low Risk', 4)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('F-Low Risk', 4)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('E-Low Risk', 4)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('D-Very Low Risk', 5)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('C-Very Low Risk', 5)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('B-Very Low Risk', 5)\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].replace('A-Very Low Risk', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need to encode\n",
    "df['MobileNo_Avl_Flag'] = df['MobileNo_Avl_Flag'].astype('category')\n",
    "df['Aadhar_flag'] = df['Aadhar_flag'].astype('category')\n",
    "df['PAN_flag'] = df['PAN_flag'].astype('category')\n",
    "df['VoterID_flag'] = df['VoterID_flag'].astype('category')\n",
    "df['Driving_flag'] = df['Driving_flag'].astype('category')\n",
    "df['Passport_flag'] = df['Passport_flag'].astype('category')\n",
    "#can encode if computation allows\n",
    "df['branch_id'] = df['branch_id'].astype('category')\n",
    "df['manufacturer_id'] = df['manufacturer_id'].astype('category')\n",
    "df['State_ID'] = df['State_ID'].astype('category')\n",
    "#encode\n",
    "df['PERFORM_CNS.SCORE.DESCRIPTION'] = df['PERFORM_CNS.SCORE.DESCRIPTION'].astype('category')\n",
    "df['Employment.Type'] = df['Employment.Type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['Employment.Type'] = le.fit_transform(df['Employment.Type'])\n",
    "df['branch_id'] = le.fit_transform(df['branch_id'])\n",
    "df['manufacturer_id'] = le.fit_transform(df['manufacturer_id'])\n",
    "df['State_ID'] = le.fit_transform(df['State_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = pd.get_dummies(df[['PERFORM_CNS.SCORE.DESCRIPTION', 'Employment.Type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print column names also**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345546, 36)\n",
      "(345546, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(new_cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, new_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345546, 43)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Employment.Type', 'PERFORM_CNS.SCORE.DESCRIPTION'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345546, 40)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:233154,:]\n",
    "x_test = df.iloc[233154:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = [int(x) for x in np.linspace(start = 1, stop = 40, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "class_weight = [{0:1,1:3},{0:1,1:4},{0:1,1:5}]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'class_weight': class_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=22, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=22, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=22, max_depth=60, bootstrap=False \n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features=40, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features=40, max_depth=10, bootstrap=True, total= 9.5min\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features=40, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features=40, max_depth=10, bootstrap=True, total= 9.2min\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features=40, max_depth=10, bootstrap=True \n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=40, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=2, max_features=40, max_depth=10, bootstrap=True, total=23.0min\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=4, max_features=40, max_depth=60, bootstrap=True \n"
     ]
    }
   ],
   "source": [
    "rf_random.fit(x, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_rf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'UniqueID': unique_id,'loan_default': y_pred})\n",
    "filename = 'submission.csv'\n",
    "submission.to_csv(filename,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
